{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data formatting\n",
    "This notebook goes through all the raster layers compiled to build the Deforestation Risk Index in Ivory Coast. It formats all layers to the same template, ensureing each pixel point for all features corresponds to the same point on the earth surface.\n",
    "\n",
    "1. helper functions\n",
    "2. time variant features:\n",
    "    * Computes cell level distance to disturbances\n",
    "    * Generates template for reporjection\n",
    "    * reprojects disturbances to template\n",
    "    * convert and export rasters to tabular format (csv)\n",
    "3. time invariant features:\n",
    "    * define resample operations for each feature\n",
    "    * reproject each feature to the same template\n",
    "    * convert each feature to a csv column, including coordinate points\n",
    "4. combine al features into a unique csv:\n",
    "    * Train set\n",
    "    * Test set\n",
    "\n",
    "### Main assumptions (Neeraj to review):\n",
    "* transformed from binary classification problem into a regression problem by reducing resolution (from 10m to 100m)\n",
    "* Projection methods for:\n",
    "    * GRA_bilinear for all features except land use and forest disturbances\n",
    "    * Mode for land use inventory\n",
    "    * Average for binary raster of forest disturbances (yieldng a 0-1 float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    from functools import reduce\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import Point, mapping\n",
    "from fiona import collection\n",
    "from fiona import transform\n",
    "from osgeo import gdal, gdalconst\n",
    "from os import path\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pahts to data on the server\n",
    "IMAGES_DATA_PATH = \"/mnt/uksa-storage/images-cdi-data/\"\n",
    "PREDICTIVE_MODELLING_DATA_PATH = \"/home/pablo/uksa-cdi/analysis/static_dri/data/\"\n",
    "# differentiate pilot (South West) and national level data\n",
    "rasters = [ 'pilot','national']\n",
    "# years to consider \n",
    "years = list(range(2016,2021))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "### reproject a raster to a given template ###\n",
    "#############################################\n",
    "def reproject_raster_to_match_template(input_file, output_file, projection_method = None, data_type = None, referencefile = \"intermediate/national_template.tif\"):\n",
    "    if(path.isfile(output_file)):\n",
    "        return\n",
    "\n",
    "    inpt = gdal.Open(input_file, gdalconst.GA_ReadOnly)\n",
    "    inputProj = inpt.GetProjection()\n",
    "    inputTrans = inpt.GetGeoTransform()\n",
    "\n",
    "    reference = gdal.Open(referencefile, gdalconst.GA_ReadOnly)\n",
    "    referenceProj = reference.GetProjection()\n",
    "    referenceTrans = reference.GetGeoTransform()\n",
    "    bandreference = reference.GetRasterBand(1)    \n",
    "    x = reference.RasterXSize \n",
    "    y = reference.RasterYSize\n",
    "\n",
    "    if data_type == None: \n",
    "        data_type = bandreference.DataType\n",
    "\n",
    "    if projection_method == None:\n",
    "        projection_method = gdalconst.GRA_Bilinear\n",
    "\n",
    "    driver= gdal.GetDriverByName('GTiff')\n",
    "    output = driver.Create(output_file,x,y,1,data_type, options = [ 'COMPRESS=LZW' ] )\n",
    "    output.SetGeoTransform(referenceTrans)\n",
    "    output.SetProjection(referenceProj)\n",
    "\n",
    "    gdal.ReprojectImage(input,output,inputProj,referenceProj,projection_method)\n",
    "\n",
    "    del output\n",
    "    \n",
    "##############################\n",
    "### time variant helpers ###\n",
    "##############################\n",
    "def distance_to_disturbance(source, target_value, outfile):\n",
    "    \"\"\" Compute distance of each cell to the nearest deforested pixel\"\"\"\n",
    "    cmd = f\"gdal_proximity.py -co BIGTIFF=YES -co COMPRESS=LZW -maxdist 4000 -nodata 4001 -ot Int16 -values {target_value} {source} {outfile} \"\n",
    "    os.system(cmd)\n",
    "    return\n",
    "\n",
    "def template(source, target, resolution):\n",
    "    \"\"\" Create template file at imposed respolution in meters\"\"\"\n",
    "    os.system(f\"rm {target}\")\n",
    "    cmd = f\"gdalwarp -co BIGTIFF=YES -co COMPRESS=LZW -tr {resolution} {resolution} {source} {target}\"\n",
    "    os.system(cmd)\n",
    "    return\n",
    "\n",
    "\n",
    "#####################\n",
    "### merge helpers ###\n",
    "#####################\n",
    "def create_dataset(year, rst):\n",
    "    \"\"\" Creates the columns of the tabularised data for the year and region selected\"\"\"\n",
    "    year_column_path = f\"intermediate/{rst}/{year}.csv\"\n",
    "    deforestation_path = (f\"intermediate/{rst}/{rst}_deforestation_{year}_ds.csv\")  \n",
    "    deforestation_path_1_lag = (f\"intermediate/{rst}/{rst}_deforestation_{year-1}_ds.csv\")  \n",
    "    distance_path_1_lag = (f\"intermediate/{rst}/distance_to_deforestation_{rst}_in_year_{year-1}_ds.csv\")\n",
    "    distance_path = (f\"intermediate/{rst}/distance_to_deforestation_{rst}_in_year_{year}_ds.csv\")\n",
    "    output_path = f\"intermediate/{rst}/time_varying_{year}.csv\"\n",
    "\n",
    "\n",
    "    length = ! wc -l < $deforestation_path_1_lag\n",
    "    command = f\"yes {year} | head -n {length[0]} > {year_column_path}\" #This writes out a column with given year\n",
    "    ! $command\\\n",
    "    \n",
    "    ! echo \"year,deforestation_share,deforestation_share_1_lag,distance_to_deforestation,distance_to_deforestation_1_lag\" > $output_path\n",
    "    ! ~/.cargo/bin/xsv cat columns $year_column_path $deforestation_path $deforestation_path_1_lag $distance_path $distance_path_1_lag >> $output_path\n",
    "    return\n",
    "\n",
    "def merge_variant_invariant(year, rst):\n",
    "    \"\"\" Merges the time variant tabularised data of year with the invariant of rst region \"\"\"\n",
    "    os.system(f'rm output/{rst}_training_{year}.csv')\n",
    "    cmd = f\"~/.cargo/bin/xsv cat columns intermediate/{rst}/time_varying_{year}.csv intermediate/{rst}/time_invariant.csv | ~/.cargo/bin/xsv slice -s 2 | ~/.cargo/bin/xsv search -s {rst}_aoi_ds 1 >> output/{rst}_training_{year}.csv\"\n",
    "    os.system(cmd)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time variant features\n",
    "### 2.1. Distance to disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance to disturbances for both pilot and national EWS since 2016\n",
    "\n",
    "for rst in rasters:\n",
    "    for y in years:\n",
    "        source = f'intermediate/{rst}_ews_disturbances_by_year.tif'\n",
    "        outfile = f\"intermediate/distance_to_deforestation_{rst}_in_year_{y}.tif\" \n",
    "        target_value = y -2014\n",
    "        distance_to_disturbance(source, target_value, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generate template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create template file (original file is 10x10 meters, new is 100 x 100, i.e. downscale by factor of 100)\n",
    "for rst in rasters:\n",
    "    source = f\"data/{rst}_ews_disturbances_by_day.tif\"\n",
    "    target = f\"intermediate/{rst}_template.tif\"\n",
    "    resolution = 100\n",
    "    template(source, target, resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Project to template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project onto template\n",
    "for rst in rasters:\n",
    "    resample_operations = []\n",
    "    for y in years:\n",
    "        # Deforestation history\n",
    "        operation = {'input_file': f\"intermediate/{rst}_deforestation_{y}.tif\",\n",
    "                   'output_file': f\"intermediate/{rst}_deforestation_{y}_ds.tif\",\n",
    "                   'resample_method': gdalconst.GRA_Average,\n",
    "                   'data_type': gdalconst.GDT_Float32}\n",
    "        resample_operations.append(operation)\n",
    "        \n",
    "        # Distance to deforestation\n",
    "        operation = {'input_file': f\"intermediate/distance_to_deforestation_{rst}_in_year_{y}.tif\",\n",
    "               'output_file': f\"intermediate/distance_to_deforestation_{rst}_in_year_{y}_ds.tif\",\n",
    "               'resample_method': gdalconst.GRA_Average,\n",
    "               'data_type': gdalconst.GDT_Float32}\n",
    "        resample_operations.append(operation)\n",
    "    \n",
    "    for o in resample_operations:\n",
    "        if path.isfile(o['input_file']):\n",
    "            \n",
    "            reproject_raster_to_match_template(o['input_file'], \n",
    "                                             o['output_file'], \n",
    "                                             o.get('resample_method', None),\n",
    "                                             o.get('data_type', None),\n",
    "                                             referencefile = f\"intermediate/{rst}_template.tif\"  \n",
    "                                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project onto template\n",
    "\n",
    "for rst in rasters:\n",
    "    resample_operations = []\n",
    "    for y in years:\n",
    "        # Deforestation history\n",
    "        operation = {'input_file': f\"intermediate/{rst}_deforestation_{y}.tif\",\n",
    "                   'output_file': f\"intermediate/{rst}_deforestation_{y}_ds.tif\",\n",
    "                   'resample_method': gdalconst.GRA_Average,\n",
    "                   'data_type': gdalconst.GDT_Float32}\n",
    "        resample_operations.append(operation)\n",
    "        \n",
    "        # Distance to deforestation\n",
    "        operation = {'input_file': f\"intermediate/distance_to_deforestation_{rst}_in_year_{y}.tif\",\n",
    "               'output_file': f\"intermediate/distance_to_deforestation_{rst}_in_year_{y}_ds.tif\",\n",
    "               'resample_method': gdalconst.GRA_Average,\n",
    "               'data_type': gdalconst.GDT_Float32}\n",
    "        resample_operations.append(operation)\n",
    "    \n",
    "    for o in resample_operations:\n",
    "        if path.isfile(o['input_file']):\n",
    "            \n",
    "            reproject_raster_to_match_template(o['input_file'], \n",
    "                                             o['output_file'], \n",
    "                                             o.get('resample_method', None),\n",
    "                                             o.get('data_type', None),\n",
    "                                             referencefile = f\"intermediate/{rst}_template.tif\"  \n",
    "                                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time invariant features\n",
    "### 3.1. Resample operations\n",
    "Define resample operations for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 6723, 7070\n",
      "Input file size is 6723, 7070\n",
      "Input file size is 6723, 7070\n",
      "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
      "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
      "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "resample_operations = []\n",
    "\n",
    "# In AOI national and pilot\n",
    "for rst in rasters:\n",
    "    cmd = f\"gdal_translate -of VRT intermediate/{rst}_template.tif intermediate/{rst}/{rst}_aoi_ds.vrt -a_nodata none\"\n",
    "    os.system(cmd)\n",
    "    \n",
    "    cmd = f'gdal_calc.py -A \"intermediate/{rst}/{rst}_aoi_ds.vrt\" --calc=\"A*0\" --outfile=\"intermediate/{rst}/{rst}_aoi_ds.tif\" --co=\"COMPRESS=LZW\"'\n",
    "    os.system(cmd)\n",
    "\n",
    "    if rst =='national':\n",
    "        path_to_aoi = path.join(IMAGES_DATA_PATH , \"Vivid/ERP_Area/ci_limite_frontiere.shp\")\n",
    "    elif rst == 'pilot':\n",
    "        path_to_aoi = path.join(IMAGES_DATA_PATH , \"Vivid/ERP_Area/ERP_Area.shp\")\n",
    "    cmd = f'gdal_rasterize -burn 1 {path_to_aoi} \"intermediate/{rst}/{rst}_aoi_ds.tif\"'\n",
    "    os.system(cmd)\n",
    "    cmd  = f'rm intermediate/{rst}/{rst}_aoi_ds.vrt'\n",
    "    os.system(cmd)\n",
    "\n",
    "# Elevation\n",
    "elevation_operation = {'input_file': path.join(IMAGES_DATA_PATH, \"SRTM/srtm_WestAfrica.tif\"),\n",
    "                       'output_file': f\"elevation_ds.tif\"}\n",
    "resample_operations.append(elevation_operation)\n",
    "\n",
    "# Slope\n",
    "slope_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"slope_CDI.tif\"),\n",
    "                   'output_file': f\"slope_ds.tif\"}\n",
    "resample_operations.append(slope_operation)\n",
    "\n",
    "# Roughness\n",
    "roughness_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"roughness_CDI.tif\"),\n",
    "                   'output_file': f\"roughness_ds.tif\"}\n",
    "resample_operations.append(roughness_operation)\n",
    "\n",
    "# Ruggedness (TRI)\n",
    "ruggedness_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"TRI_CDI.tif\"),\n",
    "                       'output_file': f\"ruggedness_ds.tif\"}\n",
    "resample_operations.append(ruggedness_operation)\n",
    "\n",
    "# Cocoa suitability\n",
    "cocoa_suitability_operation = {'input_file': path.join(IMAGES_DATA_PATH, \"Schroth/current_suitability.tif\"),\n",
    "                              'output_file': f\"cooa_suitability_ds.tif\"}\n",
    "resample_operations.append(cocoa_suitability_operation)\n",
    "\n",
    "# Hansen metrics\n",
    "\n",
    "hansen_treecover_2000_operation = {'input_file': path.join(IMAGES_DATA_PATH, \"Vivid/global_forest/Hansen_GFC-2016-v1.4_treecover2000_CDI.tif\"),\n",
    "                                   'output_file': f\"treecover_2000_ds.tif\"}\n",
    "resample_operations.append(hansen_treecover_2000_operation)\n",
    "\n",
    "### Protected status \n",
    "# create a .vrt template for each feature of the same shape as template\n",
    "!gdal_translate -of VRT intermediate/national_template.tif intermediate/protected_areas_ds.vrt -a_nodata none\n",
    "!gdal_translate -of VRT intermediate/national_template.tif intermediate/national_parks_ds.vrt -a_nodata none\n",
    "!gdal_translate -of VRT intermediate/national_template.tif intermediate/protected_id.vrt -a_nodata none\n",
    "# erase all entries inherited from template - set all rasters to 0\n",
    "!gdal_calc.py -A \"intermediate/protected_areas_ds.vrt\" --calc=\"A*0\" --outfile=\"intermediate/protected_areas_ds.tif\" --co=\"COMPRESS=LZW\"\n",
    "!gdal_calc.py -A \"intermediate/national_parks_ds.vrt\" --calc=\"A*0\" --outfile=\"intermediate/national_parks_ds.tif\" --co=\"COMPRESS=LZW\"\n",
    "!gdal_calc.py -A \"intermediate/protected_id.vrt\" --calc=\"A*0\" --outfile=\"intermediate/protected_id_ds.tif\" --co=\"COMPRESS=LZW\"\n",
    "# write tifs with protected areas \n",
    "path_to_protected_areas = path.join(IMAGES_DATA_PATH , \"Vivid/protected_areas/all_forests.shp\")\n",
    "path_to_national_parks = path.join(IMAGES_DATA_PATH , \"Vivid/protected_areas/pnr_reprojected.shp\")\n",
    "\n",
    "!gdal_rasterize -a OBJECTID_1 $path_to_protected_areas \"intermediate/protected_id_ds.tif\"\n",
    "!gdal_rasterize -burn 1 $path_to_protected_areas \"intermediate/protected_areas_ds.tif\"\n",
    "!gdal_rasterize -burn 1 $path_to_national_parks \"intermediate/national_parks_ds.tif\"\n",
    "#!gdal_rasterize -burn 1 -sql \"SELECT * FROM forests WHERE NOM='TAI' OR NOM='N''ZO'\" $path_to_protected_areas \"intermediate/national_parks_ds.tif\"\n",
    "!rm intermediate/protected_areas_ds.vrt\n",
    "!rm intermediate/national_parks_ds.vrt\n",
    "!rm intermediate/protected_id.vrt\n",
    "protected_status = ['protected_id_ds.tif',\n",
    "                    'protected_areas_ds.tif',\n",
    "                    'national_parks_ds.tif'\n",
    "                   ]\n",
    "for status in protected_status:\n",
    "    status_append = {'input_file':f'intermediate/{status}',\n",
    "                         'output_file': f'{status}'}\n",
    "    resample_operations.append(status_append)\n",
    "\n",
    "\n",
    "# Merraclim metrics\n",
    "for i in range(1,17):\n",
    "    merraclim_operation = {'input_file': path.join(IMAGES_DATA_PATH, f\"MerraClim/2_5m_mean_00s_bio{i}.tif\"),\n",
    "                         'output_file': f\"merraclim_{i}_ds.tif\"}\n",
    "    resample_operations.append(merraclim_operation)\n",
    "\n",
    "\n",
    "# Distance to permanent water\n",
    "distance_to_permanent_water_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"distance_to_permanent_river_CDI.tif\"),\n",
    "                              'output_file': f\"distance_to_permanent_river_ds.tif\"}\n",
    "resample_operations.append(distance_to_permanent_water_operation)\n",
    "\n",
    "\n",
    "# Distance to major road\n",
    "distance_to_major_road_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"distance_to_major_road.tif\"),\n",
    "                              'output_file': f\"distance_to_major_road_ds.tif\"}\n",
    "resample_operations.append(distance_to_major_road_operation)\n",
    "\n",
    "\n",
    "# Distance to road \n",
    "distance_to_road_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"distance_to_road.tif\"),\n",
    "                              'output_file': f\"distance_to_road_ds.tif\"}\n",
    "resample_operations.append(distance_to_road_operation)\n",
    "\n",
    "\n",
    "#Distance to urban settlement metrics\n",
    "esa_aggregation_levels = [10,20,50,100,200]\n",
    "esa_years = [2001,2006,2011,2015]\n",
    "distances = []\n",
    "for pair in list(itertools.product(esa_aggregation_levels, esa_years)):\n",
    "    aggregation, year = pair\n",
    "    distance_to_urban_settlement_operation = {'input_file': path.join(PREDICTIVE_MODELLING_DATA_PATH, \"esa_urban/esa_urban/distance_to_urban_cluster_over_{}_cells_year_{}.tif\".format(aggregation,year)),\n",
    "                                              'output_file': \"distance_to_urban_cluster_over_{}_cells_year_{}_ds.tif\".format(aggregation,year)\n",
    "                                             }\n",
    "    resample_operations.append(distance_to_urban_settlement_operation)\n",
    "\n",
    "# Predominant land use 2019\n",
    "predominant_land_use_operation = {'input_file': path.join(IMAGES_DATA_PATH, \"Vivid/rsac_land_use/rsac_land_use_CDI.tif\"),\n",
    "                                  'output_file': \"predominant_land_use_ds.tif\",\n",
    "                                  'resample_method': gdalconst.GRA_Mode\n",
    "                                  }\n",
    "resample_operations.append(predominant_land_use_operation)\n",
    "\n",
    "#Share closed forest 2019\n",
    "if(not path.isfile(\"intermediate/closed_forest_mask.tif\")):\n",
    "    !gdal_calc.py -A \"/mnt/uksa-storage/images-cdi-data/Vivid/rsac_land_use/rsac_land_use_CDI.tif\" --calc=\"A==5\" --outfile=intermediate/closed_forest_mask.tif --co=\"COMPRESS=LZW\"\n",
    "\n",
    "share_closed_forest_operation = {'input_file': \"intermediate/closed_forest_mask.tif\",\n",
    "                              'output_file': \"closed_forest_mask_ds.tif\"}\n",
    "resample_operations.append(share_closed_forest_operation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Reproject\n",
    "Compute each resample operation defined above. The computations need to be carried out twice, first for the whole country and then for the South West only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rst in rasters:\n",
    "    for o in resample_operations:\n",
    "        reproject_raster_to_match_template(o['input_file'], \n",
    "                                         f'intermediate/{rst}/{rst}_'+o['output_file'], \n",
    "                                         o.get('resample_method', None),\n",
    "                                         o.get('data_type', None),\n",
    "                                         f\"intermediate/{rst}_template.tif\"\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first file processed is pilot_roughness_ds\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "first file processed is national_distance_to_urban_cluster_over_10_cells_year_2015_ds\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "continuing...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Write out a CSV with all the time invariant columns\n",
    "for rst in rasters:\n",
    "    # get time invariant file names\n",
    "    time_invariant_paths = list(Path(f\"intermediate/{rst}\").glob('*_ds.tif'))\n",
    "    headers = []\n",
    "    output_file_list = []\n",
    "    # convert each invariant file to csv\n",
    "    for i,p in enumerate(time_invariant_paths):\n",
    "        old_filename = str(p)\n",
    "        stem = Path(p).stem \n",
    "        new_filename = stem + \".csv\"\n",
    "\n",
    "        if(i == 0):\n",
    "            headers.append(f\"x,y,{stem}\")\n",
    "            print(f\"first file processed is {stem}\")\n",
    "            options = \"\"\n",
    "        else:\n",
    "            headers.append(f\"{stem}\")\n",
    "            options = \"-plain\"\n",
    "\n",
    "        output_file_list.append(f\"intermediate/{rst}/{new_filename}\")\n",
    "\n",
    "        if(path.isfile(f\"intermediate/{rst}/{new_filename}\")):\n",
    "            print('continuing...')\n",
    "            continue\n",
    "\n",
    "        command = f\"./gdal2xyz.py -csv {options}  {old_filename} intermediate/{rst}/{new_filename}\"\n",
    "        print(command)\n",
    "        ! $command\n",
    "    \n",
    "    # create a unique csv with all variables as columns\n",
    "    pending = \"pending.csv\"\n",
    "    output_path = f\"intermediate/{rst}/time_invariant.csv\"\n",
    "    for i in range(len(output_file_list)):\n",
    "        print(i)\n",
    "        head = headers[i]\n",
    "        file = output_file_list[i]\n",
    "        ! echo $head > header.csv\n",
    "        ! cat  header.csv $file > append.csv\n",
    "        if i ==0:\n",
    "            ! cp append.csv $output_path\n",
    "        else:\n",
    "            ! ~/.cargo/bin/xsv cat columns append.csv $output_path > pending.csv\n",
    "            ! rm $output_path\n",
    "            ! mv $pending $output_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge datasets\n",
    "### 4.1. Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes: standard output: Broken pipe\n",
      "yes: standard output: Broken pipe\n",
      "yes: standard output: Broken pipe\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# train datasets\n",
    "rst ='pilot'\n",
    "for year in range(2017,2021):\n",
    "    create_dataset(year, rst)\n",
    "    merge_variant_invariant(year, rst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes: standard output: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# test dataset PILOT REGION\n",
    "year = 2019\n",
    "rst = 'pilot'\n",
    "create_dataset(year, rst)\n",
    "merge_variant_invariant(year, rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes: standard output: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# test dataset NATIONAL\n",
    "year = 2020\n",
    "rst = 'national'\n",
    "create_dataset(year, rst)\n",
    "merge_variant_invariant(year, rst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
